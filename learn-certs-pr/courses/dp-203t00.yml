### YamlMime:Course
title: Data Engineering on Microsoft Azure
metadata:
  title: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
  description: 'Course DP-203T00-A: Data Engineering on Microsoft Azure'
uid: course.dp-203t00
courseNumber: 'DP-203T00-A'
hoursToComplete: 96
iconUrl: /media/learn/certification/course.svg
skillsGained:
- skill: Azure의 데이터 엔지니어링 워크로드에 대한 컴퓨팅 및 저장소 옵션 살펴보기
- skill: 서버리스 SQL 풀을 사용하여 대화형 쿼리 실행 
- skill: Azure Databricks에서 데이터 탐색 및 변환 수행
- skill: Apache Spark를 사용하여 데이터 탐색, 변환 및 데이터 웨어하우스로 로드
- skill: 데이터를 데이터 웨어하우스로 수집 및 로드 
- skill: Azure Data Factory 또는 Azure Synapse Pipelines로 데이터 변환
- skill: 노트북의 데이터를 Azure Data Factory 또는 Azure Synapse Pipelines와 통합
- skill: Azure Synapse Link로 하이브리드 트랜젝션 분석 처리 (HTAP) 지원
- skill: Azure Synapse Analytics으로 종단간 보안 수행
- skill: Stream Analytics로 실시간 스트리밍 처리 수행
- skill: Event Hubs와 Azure 데이터브릭으로 스트리밍 처리 솔루션 만들기
learningPartnersLink: /learn/certifications/partners
locales:
- en
levels:
- intermediate
roles:
- data-engineer
products:
- azure
exams:
- uid: exam.dp-203
summary: |-
  이 과정에서, 학생은 Azure 데이터 플랫폼 기술을 사용하여 배치 및 실시간 분석 솔루션으로 작업하는 것과 관련된 데이터 엔지니어링에 대해서 배우게 됩니다. 학생들은 먼저 분석 솔루션을 구축하는 데 사용되는 핵심 컴퓨팅 및 스토리지 기술을 이해합니다. 학생들은 데이터 레이크의 파일에 저장된 데이터를 대화식으로 탐색하는 방법을 배우게 됩니다. Azure Synapse Analytics 또는 Azure Databricks에 있는 Apache Spark 기능을 사용하여 데이터를 로드하는 데 사용할 수 있는 다양한 수집 기술, 또는 Azure Data Factory 혹은 Azure Synapse 파이프라인을 사용하여 수집하는 방법을 배우게 됩니다. 학생들은 또한 데이터 수집에 사용되는 것과 동일한 기술을 사용하여 데이터를 변환할 수 있는 다양한 방법을 배우게 됩니다. 저장 또는 전송 중인 데이터를 보호하기 위한 보안을 구현하는 것에 대한 중요성을 이해하게 됩니다. 학생은 그런 다음 실시간 분석 솔루션을 만들기 위해 실시간 분석 시스템을 만드는 방법을 보여줄 것입니다.  

  #### 구독자 프로필
  이 과정의 주요 대상은 데이터 엔지니어링에 대해 배우고 Microsoft Azure에 존재하는 데이터 플랫폼 기술을 사용하여 분석 솔루션을 구축하는 것을 배우려는 데이터 전문가, 데이터 아키텍트 및 비즈니스 인텔리전스 전문가입니다. 이 과정의 부차적인 대상은 Microsoft Azure에 구축 된 분석 솔루션으로 작업하는 데이터 분석가 및 데이터 과학자 입니다. 
prerequisitesSection: |-
  성공적인 학생들은 cloud 컴퓨팅 및 데이터 개념에 대한 지식과 핵심 데이터 개념 및 데이터 솔루션에 대한 전문적 경험을 바탕으로 이 과정을 시작합니다.
  
  구체적으로 완료&#58;
  
  - AZ-900 - Azure Fundamentals
  - DP-900 - Microsoft Azure Data Fundamentals
outlineSection: |-
  ### 모듈 1&#58; 데이터 엔지니어링 워크로드에 대한 컴퓨팅 및 저장 옵션 살펴보기 
  이 모듈은 분석 워크로드를 구축하는 데이터 엔지니어가 사용할 수 있는 Azure 컴퓨팅 및 저장 기술 옵션애 대한 개요를 제공합니다. 이 모듈은 데이터 레이크를 조직하는 방법과 탐색, 스트리밍 및 일관 워크로드에 대한 파일을 최적화하는 방법을 알려줍니다. 학생은 일괄 처리 및 스트리밍 처리를 통해 파일을 변환할 때 데이터 레이크를 데이터 개선 수준으로 조직하는 방법을 배웁니다. 그런 다음 CSV, JSON, 및 Parquet 파일과 같은 데이터세트에 인덱스를 만들고 잠재적인 쿼리와 워크로드 가속화에 사용하는 방법을 배웁니다.  
  #### 레슨
  - Azure Synapse Analytics 소개
  - Azure Databricks 설명
  - Azure Data Lake 저장소 소개
  - Delta Lake 아키텍처 설명
  - Azure Stream Analytics를 사용하여 데이터 스트리밍 작업

  #### 랩 &#58; 데이터 엔지니어링 워크로드를 위한 대한 컴퓨팅 및 저장소 옵션 살펴보기
  *   단일 파이프라인으로 스트리밍 및 일괄 처리 결합 
  *   데이터 레이크를 파일 변환 수준으로 구성 
  *   쿼리 및 워크로드 가속화를 위한 데이터 레이크 스토리지 인덱스 
  
  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다&#58;
  - Azure Synapse Analytics 설명
  - Azure Databricks 설명
  - Azure Data Lake 저장소 설명
  - Delta Lake 아키텍처 설명
  - Azure Stream Analytics 설명
   
  ### 모듈 2&#58; Azure Synapse Analytics 서버리스 SQL 풀을 사용하여 대화형 쿼리 실행
  이 모듈에서, 학생들은 Azure Synapse Analytics의 서버리스 SQL 풀에 의해 실행되는 T-SQL 문을 통해, 데이터 레이크 및 외부 파일 소스에 저장된 파일로 작업하는 배웁니다. 학생들은 데이터 레이크에 저장된 파케이 파일과, 외부 데이터 저장소에 저장된 CSV 파일을 쿼리합니다. 다음으로 Azure Active Directory 보안 그룹을 만들고 역할-기반 접근 제어 (RBAC) 및 접근 제어 목록 (ACLs)을 통해 데이터 레이크의 파일에 대한 접근을 실행합니다.
  #### 레슨
  - Azure Synapse 서버리스 SQL 풀 기능 살펴보기
  - Azure 시냅스 서버리스 SQL 풀을 사용하여 레이크에서 데이터 뭐리
  - Azure Synapse 서버리스 SQL 풀에서 메타 데이터 개체 만들기
  - Azure Synapse 서버리스 SQL 풀에서 데이터 보안 및 사용자 관리
  
  #### 랩 &#58; 서버리스 SQL 풀을 사용하여 대화형 쿼리 실행
  - 서버리스 SQL 풀로 파케이 데이터 쿼리
  - 파케이 및 CSV 파일을 위한 외부 테이블 만들기
  - 서버리스 SQL 풀로 보기 만들기
  - 서버리스 SQL 풀을 사용할 때 데이터 레이크에서 데이터에 대한 접근 보안  
  - 역할-기반 제어 (RBAC) 및 접근 제어 목록을 사용하여 데이터 레이크 보안 구성
  
  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다&#58;
  - Azure Synapse 서버리스 SQL 풀 기능 이해
  - Azure Synapse 서버리스 SQL 풀을 사용하여 레이크에서 데이터 쿼리
  - Azure Synapse 서버리스 SQL 풀에서 메타 데이터 개체 만들기
  - Azure Synapse 서버리스 SQL 풀에서 데이터 보안 및 사용자 관리
  
  ### 모듈 3: Azure Databricks의 데이터 탐색 및 변환

  이 모듈은 다양한 Apache Spark DataFrame 방법을 사용하여 Azure Databricks에서 데이터를 탐색하고 변환하는 방법을 알려줍니다. 학생은 데이터를 탐색하고 변환하기 위해 표준 DataFrame 방법을 수행하는 방법을 배우게 됩니다. 또한 중복 데이터 제거하기, 날짜/시간 값 조작, 열 이름 바꾸기, 및 데이터 집계와 같은 더 고급 작업을 수행하는 방법도 배우게 됩니다.

  #### 레슨

  *   Azure Databricks 설명

  *   Azure Databricks 에서 데이터 읽고 쓰기

  *   Azure Databricks에서 DataFrames으로 작업

  *   Azure Databricks에서 DataFrames 고급 방법으로 작업


  #### 랩 : Azure Databricks에서 데이터 탐색 및 변환

  ####
  *   데이터 탐색 및 필터링을 위해 Azure Databricks의 DataFrames 사용
  *   더 빠른 후속 쿼리를 위해 DataFrame 캐시
  *   중복 데이터 제거
  *   날짜/ 시간 값 조작
  *   DataFrame 열 제거 및 이름 바꾸기
  *   DataFrame에 저장된 데이터 집계

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Databricks 설명

  *   Azure Databricks에서 데이터 읽고 쓰기

  *   Azure Databricks에서 DataFrames으로 작업하기

  *   Azure Databricks에서 DataFrames 고급 방법으로 작업하기


  ### 모듈 4: Apache Spark를 사용하여 데이터 탐색, 변환, 및 데이터 웨어하우스로 로드

  이 모듈은 데이터 레이크에 저장된 데이터를 탐색하고, 데이터를 변환하고, 데이터를 관계형 데이터 저장소에 로드하는 방법을 알려줍니다. 학생은 파켓 및 JSON 파일을 탐색하고 계층 구조로 JSON 파일을 쿼리하고 변환하기 위해 기술을 사용하게 됩니다. 그런 다음 학생은 Apache Spark를 사용하여 데이터를 데이터 웨어하우스에 로드하고 데이터 레이크의 파켓 데이터를 전용 SQL 풀의 데이터와 결합합니다.

  #### 레슨

  *   Azure Synapse Analytics의 Apache Spark를 사용한 빅 데이터 엔지니어링 이해

  *   Azure Synapse Analytics의 Apache Spark 노트북으로 데이터 수집

  *   Azure Synapse Analytics의 Apache Spark 풀에서 DataFrames으로 데이터 변환

  *   Azure Synapse Analytics에서 SQL 및 Apache Spark 풀 통합


  #### 랩 : Apache Spark를 사용하여 데이터를 탐색, 변환, 및 데이터 웨어하우스로 로드

  ####
  *   Synapse Studio에서 데이터 탐색 수행
  *   Azure Synapse Analytics의 Spark 노트북으로 데이터 수집
  *   Azure Synapse Analytics의 Spark 풀에서 DataFrames으로 데이터 변환
  *   Azure Synapse Analytics에서 SQL 및 Spark 풀 통합

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Synapse Analytics에서 Apache Spark를 사용한 빅 데이터 엔지니어링 설명

  *   Azure Synapse Analytics의 Apache Spark 노트북으로 데이터 수집

  *   Azure Synapse Analytics의 Apache Spark 풀에서 DataFrames으로 데이터 변환

  *   Azure Synapse Analytics에서 SQL 및 Apache Spark 풀 통합

  ### 모듈 5: 데이터 웨어하우스로 데이터 수집 및 로드

  이 모듈은 학생들에게 T-SQL 스크립트 및 Synapse Analytics 통합 파이프라인을 통해 데이터를 데이터 웨어하우스로 수집하는 방법을 알려줍니다. 학생은 T-SQL을 사용하여 PolyBase 및 COPY가 있는 SQL 풀 전용 Synapse로 데이터를 로드하는 방법을 배우게 됩니다. 또한 학생은 페타바이트-규모의 데이터 수집을 위한 Azure Synapse 파이프라인에서 복사 활동과 함께 워크로드 관리를 사용하는 방법도 배우게 됩니다.

  #### 레슨

  *   Azure Synapse Analytics에서 데이터 로드 모범 사례 사용

  *   Azure Data Factory로 페타바이트-규모 수집


  #### 랩 : 데이터를 데이터 웨어하우스로 수집 및 로드 

  ####
  *   Azure Synapse Pipelines로 페타바이트-규모 수집 수행
  *   T-SQL을 사용하여 PolyBase 그리고 COPY로 데이터 가져오기
  *   Azure Synapse Analytics에서 데이터 로드 모범 사례 사용

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Synapse Analytics에서 데이터 로드 모범 사례 사용

  *   Azure Data Factory로 페타바이트-규모 수집


  ### 모듈 6: Azure Data Factory 또는 Azure Synapse Pipelines로 데이터 변환

  이 모듈은 학생들에게 여러 데이터 소스에서 수집하기 위한 데이터 통합 파이프라인을 구축하고, 매핑 데이터 흐름을 사용하여 데이터를 변환하고, 하나 이상의 데이터 싱크로 데이터 이동을 수행하는 방법을 알려줍니다.

  #### 레슨

  *   Azure Data Factory 또는 Azure Synapse Pipelines와 데이터 통합

  *   Azure Data Factory 또는 Azure Synapse Pipelines으로 대규모 코드-없는 변환


  #### 랩 : Azure Data Factory 또는 Azure Synapse Pipelines으로 데이터 변환

  ####
  *   Azure Synapse Pipelines으로 대규모 코드-없는 변환 실행
  *   형식이 잘못된 CSV 파일을 가져오기 위한 데이터 파이프라인 생성
  *   매핑 데이터 흐름 생성

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Data Factory로 데이터 통합 수행

  *   Azure Data Factory로 대규모 코드-없는 변환 수행
  
  ### 모듈 7: Azure Synapse Pipelines에서 데이터 이동 및 변환 오케스트레이션

  이 모듈에서는, 연결된 서비스를 만들고, Azure Synapse Pipelines에서 노트북을 사용하여 데이터 이동 및 변환을 오케스트레이션하는 방법을 배우게 됩니다. 

  #### 레슨

  *   Azure Data Factory에서 데이터 이동 및 변환 오케스트레이션


  #### 랩 : Azure Synapse Pipelines에서 데이터 이동 및 변환 오케스트레이션

  ####
  *  Azure Data Factory 또는 Azure Synapse Pipelines와 노트북의 데이터 통합

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Synapse Pipelines에서 데이터 이동 및 변환 오케스트레이션


  ### 모듈 8: Azure Synapse Analytics를 사용한 종단 간 보안

  이 모듈에서, 학생들은 Synapse Analytics 작업 영역 및 해당 지원 인프라를 보호하는 방법을 배우게 됩니다. 학생은 SQL Active Directory Admin을 관찰하고, IP 방화벽 규칙을 관리하고, Azure Key Vault로 비밀을 관리하고 서비스와 파이프라인 활동에 연결된 Key Vault를 통해 이러한 비밀에 액세스합니다. 학생은 전용 SQL 풀을 사용할 때 열-수준 보안, 행-수준 보안, 및 dynamic 데이터 마스킹을 구현하는 방법을 이해하게 됩니다. 

  #### 레슨

  *   Azure Synapse Analytics에서 데이터 웨어하우스 보안

  *   Azure Key Vault에서 비밀 구성 및 관리

  *   민감한 데이터를 위한 규정 준수 제어 구현


  #### 랩 : Azure Synapse Analytics를 사용한 종단 간 보안

  ####
  *   Azure Synapse Analytics 지원 인프라 보안 
  *   Azure Synapse Analytics 작업 영역 및 관리 서비스 보안 
  *   Azure Synapse Analytics 작업 영역 데이터 보안

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Synapse Analytics에서 데이터 웨어하우스 보안

  *   Azure Key Vault에서 비밀 구성 및 관리

  *   민감한 데이터를 위한 규정 준수 제어 구현
  
  ### 모듈 9: Azure Synapse Link로 Hybrid Transactional Analytical Processing (HTAP) 지원

  이 모듈에서, 학생들은 Azure Synapse Link를 사용하여 Azure Cosmos DB 계정을 Synapse 작업 영역에 원활하게 연결하는 방법을 배우게 됩니다. 학생은 Synapse 링크를 활성화하고 구성하는 방법을 이해한 다음, Apache Spark 및 SQL 서버리스를 사용하여 Azure Cosmos DB 분석 저장소를 쿼리하는 방법을 이해하게 됩니다.

  #### 레슨

  *   Azure Synapse Analytics를 사용하여 하이브리드 트랜잭션 및 분석 처리 디자인

  *   Azure Cosmos DB로 Azure Synapse Link 구성

  *   Apache Spark 풀로 Azure Cosmos DB 쿼리

  *   서버리스 SQL 풀로 Azure Cosmos DB 쿼리


  #### 랩 : Azure Synapse Link로 Hybrid Transactional Analytical Processing (HTAP) 지원

  ####
  *   Azure Cosmos DB로 Azure Synapse Link  구성
  *   Synapse Analytics 용 Apache Spark으로 Azure Cosmos DB 쿼리
  *   Azure Synapse Analytics 용 서버리스 SQL 풀로 Azure Cosmos DB 쿼리

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Synapse Analytics를 사용하여 하이브리드 트랜잭션 및 분석 처리 디자인

  *   Azure Cosmos DB로 Azure Synapse Link 구성

  *   Azure Synapse Analytics 용 Apache Spark으로 Azure Cosmos DB 쿼리

  *   Azure Synapse Analytics 용 SQL 서버리스로 Azure Cosmos DB 쿼리


  ### 모듈 10: Stream Analytics를 사용한 실시간 스트림 처리

  이 모듈에서, 학생들은 Azure Stream Analytics를 사용하여 스트리밍 데이터를 처리하는 방법을 배우게 됩니다. 학생은 차량 원격 측정 데이터를 Event Hubs로 수집한 다음, Azure Stream Analytics의 다양한 창 기능을 사용하여, 해당 데이터를 실시간으로 처리하게 됩니다. Azure Synapse Analytics에 데이터를 출력합니다. 마지막으로, 학생은 처리량을 늘이기 위해 Stream Analytics 작업을 확장하는 방법을 배우게 됩니다.

  #### 레슨

  *   Azure Event Hubs를 사용하여 Big Data 애플리케이션을 위한 안정적인 메시징 활성화

  *   Azure Stream Analytics를 사용하여 데이터 스트림 작업

  *   Azure Stream Analytics로 데이터 스트림 수집


  #### 랩 : Stream Analytics로 실시간 스트림 처리

  ####
  *   Stream Analytics를 사용하여 Event Hubs의 실시간 데이터 처리
  *   Stream Analytics 윈도우 기능을 사용하여 Synapse Analytics에 대한 집계 및 출력 구축
  *   Azure Stream Analytics 작업을 확장하여 분할을 통한 처리량 증가
  *   병렬화를 최적화하기 위해 스트림 입력을 재분할 

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Event Hubs를 사용하여 Big Data 애플리케이션을 위한 안정적인 메시징 활성화

  *   Azure Stream Analytics를 사용하여 데이터 스트림 작업

  *   Azure Stream Analytics로 데이터 스트림 수집

  ### 모듈 11: Event Hubs 및 Azure Databricks를 사용하여 스트림 처리 솔루션 만들기

  이 모듈에서, 학생들은 Azure Databricks의 Event Hubs 및 Spark Structured Streaming을 사용하여 스트리밍 데이터를 대규모로 수집하고 처리하는 방법을 배우게 됩니다. 학생은 Structured Streaming의 주요 기능과 사용을 배우게 됩니다. 학생은 데이터 덩어리를 집계하고 워터마킹을 적용하여 오래된 데이터를 제거하기 위해 슬라이딩 윈도우를 구현합니다. 마지막으로, 학생은 스트림을 읽고 쓰기 위해 Event Hubs에 연결하게 됩니다.

  #### 레슨

  *   Azure Databricks structured streaming으로 스트리밍 데이터 처리


  #### 랩 : Event Hubs 및 Azure Databricks를 사용하여 스트림 처리 솔루션 만들기

  ####
  *   Structured Streaming의 주요 기능 및 사용 탐색
  *   파일에서 데이터를 스트리밍하고 분산 파일 시스템에 기록 
  *   슬라이딩 윈도우를 사용하여 모든 데이터가 아닌 데이터 덩어리 집계 
  *   워터마킹을 적용하여 오래된 데이터 제거
  *   Event Hubs에 연결하여 스트림 읽고 쓰기

  이 모듈을 완료 후, 학생들은 다음을 할 수 있게 됩니다:

  *   Azure Databricks structured streaming를 사용하여 스트리밍 데이터 처리


